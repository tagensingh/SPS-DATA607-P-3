---
title: "data607proj3"
author: "Richard"
date: "3/18/2021"
output: html_document
---
# packages
```{r}
library(tidyverse)
library(wordcloud)
```

# loading data

```{r}
url = 'https://raw.githubusercontent.com/tagensingh/SPS-DATA607-P-3/main/indeed_job_dataset.csv'
data = read.csv(url)
dim(data)
```

# functions used

```{r}
#function that transforms "python list" string into R vector
clean_string = function(string){
list = str_replace(string,"\\[","") %>%
  str_replace("\\]","") %>%
  str_replace_all("\\'","") %>%
  str_split(",")
return (trimws(list[[1]]))
}
```


# cleaning data


#### job title

```{r}
# subset job titles
job_title = unique(data[c('Job_Title','Job_Type')])
head(job_title)
```

#### company

```{r}
# subset companies
companies = unique(data[c('Company','No_of_Reviews','No_of_Stars','Company_Revenue','Company_Employees','Company_Industry')])
# drop nulls
companies = drop_na(companies)
head(companies)
```

#### jobs

```{r}
# subset jobs
jobs = data[c('X','Job_Title','Company','Queried_Salary','Date_Since_Posted','Location','Link')]
head(jobs)
```

#### skills

```{r}
data = data[data$No_of_Skills>0,]
x = data$X
strings = data$Skill
count = c()
X = c()
skill_list = c()

# create vector count
for (string in strings){
  count = c(count,length(clean_string(string)))
}

#create skills dataframe
for (i in seq(length(count))){
  X = c(X,rep(x[i],count[i]))
  skill_list = c(skill_list,clean_string(strings[i]))
}

skills = data.frame(X,skill_list)
head(skills)
```

# download tables as csv

```{r}
#write.csv(job_title,"job_title.csv",row.names=FALSE)
#write.csv(companies,"companies.csv",row.names=FALSE)
#write.csv(jobs,"jobs.csv",row.names=FALSE)
#write.csv(skills,"skills.csv",row.names=FALSE)
```

# EDA

#### most popular skills

```{r}
# most popular skills
skills %>%
  group_by_at('skill_list')%>%
  summarise(percent = n()/dim(skills)[1])%>%
  arrange(desc(percent))%>%
  head(10)%>%
  ggplot(aes(reorder(skill_list,percent),percent))+geom_bar(stat = 'identity')+coord_flip()+labs(x = 'Skills',title = "Most Desired Data Science Skills Skills")

```

#### wordcloud

```{r}
skill_count = skills %>%
  group_by(skill_list)%>%
  summarise(frequency = n())%>%
  arrange(desc(frequency))
  

wordcloud(skill_count$skill_list,skill_count$frequency,min.freq = 5,max.words=150, random.order=FALSE, rot.per=0.1,            colors=brewer.pal(8, "Dark2"))


```

```{r}

job_skills = merge(jobs,skills,on = 'X')

ny = job_skills[job_skills["Location"] == "NY",]

ny %>% 
  group_by(skill_list)%>%
  summarise(percent = n()/dim(skills)[1])%>%
  arrange(desc(percent))%>%
  head(10)%>%
  ggplot(aes(reorder(skill_list,percent),percent))+geom_bar(stat = 'identity')+coord_flip()+labs(x = 'Skills',title = "Most Desired Data Science Skills Skills in NY")
```


